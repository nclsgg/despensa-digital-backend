package main

import (
	"fmt"
	"log"
	"time"

	"github.com/nclsgg/despensa-digital/backend/internal/modules/llm/model"
	"github.com/nclsgg/despensa-digital/backend/internal/modules/llm/service"
)

// Exemplo de uso do m√≥dulo LLM
func main() {
	fmt.Println("=== Exemplo de uso do m√≥dulo LLM ===")

	// 1. Criar servi√ßo LLM
	llmService := service.NewLLMService()

	// 2. Configurar provedor OpenAI
	openAIConfig := &model.LLMConfig{
		Provider:      model.ProviderOpenAI,
		APIKey:        "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", // Em produ√ß√£o, usar vari√°veis de ambiente
		Model:         "gpt-3.5-turbo",
		MaxTokens:     2000,
		Temperature:   0.7,
		Timeout:       30 * time.Second,
		RetryAttempts: 3,
	}

	// 3. Adicionar configura√ß√£o do provedor
	if err := llmService.AddProviderConfig("openai", openAIConfig); err != nil {
		log.Printf("Erro ao configurar provedor OpenAI: %v", err)
		return
	}

	fmt.Printf("‚úÖ Provedor OpenAI configurado com sucesso\n")
	fmt.Printf("üìã Provedores dispon√≠veis: %v\n", llmService.GetAvailableProviders())
	fmt.Printf("üéØ Provedor ativo: %s\n", llmService.GetCurrentProvider())

	// 4. Demonstrar constru√ß√£o de prompts
	promptBuilder := service.NewPromptBuilder()

	systemTemplate := `Voc√™ √© um chef especialista em {{cuisine}}. 
Ajude a criar receitas com ingredientes dispon√≠veis: {{ingredients}}.
Tempo dispon√≠vel: {{time}} minutos.`

	variables := map[string]string{
		"cuisine":     "culin√°ria brasileira",
		"ingredients": "arroz, feij√£o, carne, tomate, cebola",
		"time":        "45",
	}

	systemPrompt, err := promptBuilder.BuildSystemPrompt(systemTemplate, variables)
	if err != nil {
		log.Printf("Erro ao construir prompt: %v", err)
		return
	}

	fmt.Printf("\nü§ñ System Prompt constru√≠do:\n%s\n", systemPrompt)

	// 5. Demonstrar templates de receita
	recipeTemplates := service.GetRecipePromptTemplates()
	fmt.Printf("\nüìù Template de sistema para receitas dispon√≠vel (tamanho: %d caracteres)\n",
		len(recipeTemplates.SystemPrompt))
	fmt.Printf("üìù Template de usu√°rio para receitas dispon√≠vel (tamanho: %d caracteres)\n",
		len(recipeTemplates.UserPrompt))

	// 6. Estimar tokens (estimativa simples)
	tokens := len(systemPrompt) / 4 // ~4 caracteres por token
	fmt.Printf("üìä Tokens estimados para o prompt: %d\n", tokens)

	// 7. Mostrar informa√ß√µes do provedor
	providerInfo, err := llmService.GetProviderInfo()
	if err != nil {
		log.Printf("Erro ao obter informa√ß√µes do provedor: %v", err)
	} else {
		fmt.Printf("\nüîß Informa√ß√µes do provedor:\n")
		for key, value := range providerInfo {
			fmt.Printf("  - %s: %v\n", key, value)
		}
	}

	fmt.Println("\n‚ú® M√≥dulo LLM configurado e pronto para uso!")
	fmt.Println("\nüìö Pr√≥ximos passos:")
	fmt.Println("  1. Integrar com sistema de itens da despensa")
	fmt.Println("  2. Configurar rotas e handlers REST")
	fmt.Println("  3. Adicionar suporte a outros provedores (Anthropic, Ollama, etc.)")
	fmt.Println("  4. Implementar sistema de templates persistentes")
	fmt.Println("  5. Adicionar sistema de m√©tricas e monitoramento")
}
